{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide and Deep Networks\n",
    "\n",
    "Nick Chao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation (40 points total)\n",
    "[10 points] Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis. Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created). \n",
    "\n",
    "[10 points] Identify groups of features in your data that should be combined into cross-product features. Provide justification for why these features should be crossed (or why some features should not be crossed). \n",
    "\n",
    "[10 points] Choose and explain what metric(s) you will use to evaluate your algorithmâ€™s performance. You should give a detailed argument for why this (these) metric(s) are appropriate on your data. That is, why is the metric appropriate for the task (e.g., in terms of the business case for the task). Please note: rarely is accuracy the best evaluation metric to use. Think deeply about an appropriate measure of performance.\n",
    "\n",
    "[10 points] Choose the method you will use for dividing your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Shuffle splits? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. Convince me that your cross validation method is a realistic mirroring of how an algorithm would be used in practice. \n",
    "\n",
    "### Modeling (50 points total)\n",
    "[20 points] Create several combined wide and deep networks to classify your data using Keras. Visualize the performance of the network on the training data and validation data in the same plot versus the training iterations. Try to use the \"history\" return parameter that is part of Keras \"fit\" function.\n",
    "\n",
    "[20 points] Investigate generalization performance by altering the number of layers in the deep branch of the network. Try at least two different number of layers. Use the method of cross validation and evaluation metric that you argued for at the beginning of the lab. \n",
    "\n",
    "[10 points] Compare the performance of your best wide and deep network to a standard multi-layer perceptron (MLP) using the receiver operating characteristic and area under the curve.  Use proper statistical method to compare the performance of different models.  \n",
    "\n",
    "### Exceptional Work (10 points total)\n",
    "You have free reign to provide additional analyses.\n",
    "One idea (required for 7000 level students): Capture the embedding weights from the deep network and perform t-SNE clustering on the output of these embedding layers. That is, pass the observations into the network, save the embedded weights (called embeddings), and then perform clustering of these output embeddings. Visualize and explain the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my dataset, I chose to use the dataset I've been using for the last two labs which is the 2009 American Community Survey. The goal of this dataset is to determine whether or not a person has an income greater than 100,000 dollars based on qualities about them such as sex, age, race, place of work, etc. This dataset starts with over 3 million entrees and almost 300 attributes which will eventually be narrowed down to 1.3 million entrees and 13 attributes.\n",
    "\n",
    "\n",
    "|Attribute|Description|Type|Example|\n",
    "|:---:|:---:|:---:|:---:|\n",
    "| CIT | Citizenship Status | Int | 1. Citizen, 0. Non-citizen |\n",
    "| AGEP | Age | Int | 23\n",
    "| COW | Class of Worker | Float | 3. Local Government, 4. State Government |\n",
    "| ENG | Ability to speak English  | Int | 1. Speaks English, 0. Doesn't Speak English |\n",
    "| MAR | Marital Status | Int | 1. Married, 2. Widowed |\n",
    "| MIL | Military Service | Int | 1. Yes, 0. No |\n",
    "| SCHL | Educational Attainment  | Float | 21 Bachelor's Degree, 22 Master's Degree |\n",
    "| SEX | Sex      | Int | True. Male |\n",
    "| DIS | Disability | Int | True. Disabled |\n",
    "| PINCP | Total Person's Income | Float\n",
    "| POWSP | Place of work | Float | 048 Texas, 049 Utah |\n",
    "| RAC1P | Detailed Race Code | Int | 1 White, 6 Asian |\n",
    "| FOD1P | Field of Degree | Float | 2407 Computer Engineering, 2408 Electrical Engineering |\n",
    "\n",
    "The reamining features we keep as they are attributes that are likely related to one's personal income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #importing dependancies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.utils.estimator_checks import check_estimator\n",
    "# from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import KFold, ShuffleSplit\n",
    "# from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# from sklearn.metrics import make_scorer\n",
    "# from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27.3 s\n",
      "Wall time: 26 s\n"
     ]
    }
   ],
   "source": [
    "%time dataA = pd.read_csv('../data/ss09pusa.csv')\n",
    "%time dataB = pd.read_csv('../data/ss09pusb.csv')\n",
    "merged = pd.concat([dataA,dataB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3030728 entries, 0 to 1466654\n",
      "Data columns (total 13 columns):\n",
      "CIT      int64\n",
      "AGEP     int64\n",
      "COW      float64\n",
      "ENG      float64\n",
      "MAR      int64\n",
      "MIL      float64\n",
      "SCHL     float64\n",
      "SEX      int64\n",
      "DIS      int64\n",
      "PINCP    float64\n",
      "POWSP    float64\n",
      "RAC1P    int64\n",
      "FOD1P    float64\n",
      "dtypes: float64(7), int64(6)\n",
      "memory usage: 323.7 MB\n"
     ]
    }
   ],
   "source": [
    "cols_to_save = ['CIT','AGEP','COW','ENG','MAR','MIL','SCHL','SEX','DIS','PINCP','POWSP','RAC1P','FOD1P']\n",
    "new_data = merged.filter(items=cols_to_save)\n",
    "new_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change citizenship to Int.\n",
    "# 1-4 is a citizen (true) and 5 is not a citizen (false)\n",
    "\n",
    "new_data.CIT.replace(to_replace = range(5),\n",
    "                    value=[1,1,1,1,0],\n",
    "                    inplace=True)\n",
    "new_data['CIT'] = new_data['CIT'].astype('bool')\n",
    "\n",
    "\n",
    "# Change Ability to Speak English to boolean\n",
    "# b is N/A but it would be a good assumption to assume they speak English\n",
    "new_data['ENG']=new_data['ENG'].fillna(1)\n",
    "# 1-2 speaks English well or very well, 3-4 speaks English not well or not at all.\n",
    "new_data.ENG.replace(to_replace = range(4),\n",
    "                    value=[1,1,0,0],\n",
    "                    inplace=True)\n",
    "new_data['ENG'] = new_data['ENG'].astype('bool')\n",
    "\n",
    "\n",
    "# Change Military Status to Boolean\n",
    "# b is N/A because less than 17 years old so lets just change this to 0\n",
    "new_data['MIL']=new_data['MIL'].fillna(0)\n",
    "# 1-3 Yes, 4-5 No\n",
    "new_data.MIL.replace(to_replace = range(5),\n",
    "                    value=[1,1,1,0,0],\n",
    "                    inplace=True)\n",
    "new_data['MIL'] = new_data['MIL'].astype('bool')\n",
    "\n",
    "\n",
    "# Change Sex to bool\n",
    "# 1 is male, 2 is female. Changing 2 to 0 for boolean conversion\n",
    "new_data.SEX.replace(to_replace = range(2),\n",
    "                    value=[1,0],\n",
    "                    inplace=True)\n",
    "new_data['SEX'] = new_data['SEX'].astype('bool')\n",
    "\n",
    "\n",
    "# Change DIS to bool\n",
    "# 1 is disabled, 2 is no disability. Changing 2 to 0 for boolean conversion\n",
    "new_data.DIS.replace(to_replace = range(2),\n",
    "                    value=[1,0],\n",
    "                    inplace=True)\n",
    "new_data['DIS'] = new_data['DIS'].astype('bool')\n",
    "\n",
    "\n",
    "# Change Educational Atttainment to INT\n",
    "# bb is N/A for less than 3 years old.\n",
    "new_data['SCHL']=new_data['SCHL'].fillna(0)\n",
    "# For this classification lets simplify some of these education levels.\n",
    "# 0 between No schooling and Grade 8\n",
    "# 1 between Grade 9 and Grade 12 no diploma\n",
    "# 2 for High School degree or GED\n",
    "# 3 Some college to Associate's degree\n",
    "# 4 Bachelor's Degree\n",
    "# 5 Master's Degree\n",
    "# 6 Professional degree or Doctorate\n",
    "new_data.SCHL.replace(to_replace = range(25),\n",
    "                    value=[0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,2,2,3,3,3,4,5,6,6],\n",
    "                    inplace=True)\n",
    "new_data['SCHL'] = new_data['SCHL'].astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete younger than 18\n",
    "new_data = new_data[new_data.AGEP >= 18]\n",
    "#new_data\n",
    "\n",
    "# Field of Study  -> 0\n",
    "# Class of Worker -> Remove if Null\n",
    "# Place of Work   -> Remove if Null\n",
    "\n",
    "new_data['FOD1P'].fillna(0, inplace=True)\n",
    "new_data = new_data[pd.notnull(new_data['COW'])]\n",
    "new_data = new_data[pd.notnull(new_data['POWSP'])]\n",
    "\n",
    "# Convert the Floats to Ints\n",
    "# COW, POWSP, FOD1P, PINCP\n",
    "\n",
    "new_data['COW'] = new_data['COW'].astype('int')\n",
    "new_data['POWSP'] = new_data['POWSP'].astype('int')\n",
    "new_data['FOD1P'] = new_data['FOD1P'].astype('int')\n",
    "new_data['PINCP'] = new_data['PINCP'].astype('int')\n",
    "\n",
    "future_data = new_data.copy(deep=False) # saving a copy for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_0 = new_data.PINCP <= 99999\n",
    "column_name = 'PINCP'\n",
    "new_data.loc[mask_0, column_name] = 0\n",
    "\n",
    "mask_1 = new_data.PINCP > 99999\n",
    "column_name = 'PINCP'\n",
    "new_data.loc[mask_1, column_name] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people in each class:\n",
      "0: 1209410\n",
      "1: 128869\n"
     ]
    }
   ],
   "source": [
    "# Lets see how the income classes have split...\n",
    "print('Number of people in each class:')\n",
    "for value in new_data.PINCP.unique(): \n",
    "    print(str(value)+': ' +str(len(new_data[new_data['PINCP'] == value])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1338279 entries, 1 to 1466654\n",
      "Data columns (total 13 columns):\n",
      "Citizenship        1338279 non-null bool\n",
      "Age                1338279 non-null int64\n",
      "Class of Work      1338279 non-null int32\n",
      "Speaks English     1338279 non-null bool\n",
      "Martial Status     1338279 non-null int64\n",
      "Military Status    1338279 non-null bool\n",
      "Education Level    1338279 non-null int32\n",
      "Male               1338279 non-null bool\n",
      "Disabled?          1338279 non-null bool\n",
      "Income             1338279 non-null int32\n",
      "Place of Work      1338279 non-null int32\n",
      "Race               1338279 non-null int64\n",
      "Field of Study     1338279 non-null int32\n",
      "dtypes: bool(5), int32(5), int64(3)\n",
      "memory usage: 72.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Finally, let's rename some of these columns so they make more sense.\n",
    "new_data.rename(columns={'CIT': 'Citizenship','AGEP': 'Age','COW': 'Class of Work','ENG': 'Speaks English','MAR': 'Martial Status','MIL': 'Military Status','SCHL': 'Education Level','SEX': 'Male','DIS': 'Disabled?','PINCP': 'Income','POWSP': 'Place of Work','RAC1P': 'Race','FOD1P': 'Field of Study'}, inplace=True)\n",
    "new_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = ['Citizenship', 'Age', 'Class of Work', 'Speaks English', 'Martial Status', 'Military Status', \n",
    "               'Education Level', 'Male', 'Disabled?', 'Place of Work', 'Race', 'Field of Study']\n",
    "\n",
    "df_class = ['Income']\n",
    "\n",
    "X = new_data[df_features]\n",
    "y = new_data[df_class]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Determine if a person's income is above $100,000.\n",
    "\n",
    "Since my chosen task is a binary classification task, we need to determine what type of evaluation metric works best for this case. We can start by establishing a business case. Let's say an advertising agency is attemping to solve this problem to determine what type of ads should be targeted towards a person based on their income. For example, cheaper products for people of lower income and expensive products for people of higher income. Targeting viewers with the wrong type of ads would not only be pointless, but costly as it is unlikely consumers would purchase the advertised product. \n",
    "\n",
    "In this case, we would want high recall and precision. A good recall would be the ability for the model to identify all person's will incomes above 100,000 and mark them as so. A high precision  is the ability for the model to be correct when it claims a person's income is above 100,000. Utilizing F-Score will allow us to evaluate the model using both recall and precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing\n",
    "\n",
    "With regards to splitting the data for training and testing purposes, I am going to split the data into 80% for training and 20% for testing, ensuring that both sets are equally portional. Since my data set is very large I should not have a problem being able to do this and cross validation should not be neccessary as there is over a million entres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people in each class:\n",
      "0: 1209410\n",
      "1: 128869\n",
      "Number of people in each class:\n",
      "0: 967500\n",
      "1: 103123\n",
      "Number of people in each class:\n",
      "0: 241910\n",
      "1: 25746\n"
     ]
    }
   ],
   "source": [
    "# Double checking to ensure that the split is evenly proportion\n",
    "print('Number of people in each class:')\n",
    "for value in new_data.Income.unique(): \n",
    "    print(str(value)+': ' +str(len(new_data[new_data['Income'] == value])))\n",
    "    \n",
    "print('Number of people in each class:')\n",
    "for value in y_train.Income.unique(): \n",
    "    print(str(value)+': ' +str(len(y_train[y_train['Income'] == value])))\n",
    "    \n",
    "print('Number of people in each class:')\n",
    "for value in y_test.Income.unique(): \n",
    "    print(str(value)+': ' +str(len(y_test[y_test['Income'] == value])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
